# Capstone Project Using R

## Table of Contents

 1. [Scenario](#1scenario)  

 2. [Ask](#2ask)  
   2.1 Business Task  

 3. [Prepare](#3prepare)  
   3.1 Dataset used  
   3.2 Information about our dataset  
   3.3 Data organization and verification  
   3.4 Data limitations  

 4. [Process](#4process)  
   4.1 Installing packages  
   4.2 Load libraries  
   4.3 Import files  
   4.4 Preview datasets  
   4.5 Cleaning and formatting  
   4.6 Merging datasets  

 5. [Analyze and Share](#5analyze-and-share)  
   5.1  
   5.2  
   5.3  

 6. [Act (Recommendations)](#6act-recommendations) 

***
&nbsp;

## 1.Scenario

I am a junior data analyst working on the marketing analyst team at Bellabeat, a high-tech manufacturer of health-focused products for women.  I have been asked to focus on one of Bellabeat’s products and analyze smart device data to gain insight into how consumers are using their smart devices. The insights that I discover will then help guide marketing strategy for the company. I will present my analysis to the Bellabeat executive team along with my high-level recommendations for Bellabeat’s marketing strategy.

## 2.Ask

### **2.1 Business Task**

 The business task is to analyze non-Bellabeat smart device usage, specifically FitBit Fitness Tracker data, to gain insights into how consumers are using the devices and identify trends to help guide the Bellabeat marketing strategy.

***

## 3.Prepare

&nbsp;

### **3.1 Dataset used**

 The dataset that was used for the analysis is the FitBit Fitness Tracker Data that is available on [Kaggle](https://www.kaggle.com/datasets/arashnic/fitbit) under the CC0: Public Domain license. 

### **3.2 Information about our dataset**

 The dataset was generated by respondents to a distributed survey via Amazon Mechanical Turk between 2016-03-12 and 2016-05-12. There were thirty FitBit users that consented to the submission of personal data from their device.

### **3.3 Data organization and verification**

 The dataset is stored in 18 .csv files. There are 15 that are stored in long format and three of them are also available in wide format. The datasets consist of the following information: activity metrics, calories, sleep records, metabolic equivalent of tasks (METs), heart rate and steps.

### **3.4 Data limitations**

 There were concerns and limitations with using the dataset.  

 1. The data is outdated, it is seven years old now.
 2. The sample size of participants is 30. I think that if we had more time to gather additional data that we should, but 30 can still be used. By using the data of only 30 participants we may not be able to apply some insights in a larger scope. 
 3. The data was collected for 31 days. We may not be able to see trends emerge that would require year long data. Since it's only 31 days we may also not be able to say whether or not the habits are consistent for each user. 
 4. It is missing demographic information. Bellabeat's products are produced with women in mind, so using data that does not include gender information may not produce results that will be applicable. 
 5. Some of the available files do not contain a full 31 days of data collected. 

***

## 4.Process

 I used R with RStudio to do the data processing, analysis and some preliminary visualizations. I also used Tableau to produce other visualizations. 

Before getting started in R, I used Google Sheets to get a look at the data contained in each file. I noticed that the *DailyActivity* file contained all data from the files that contained Daily in the title. I decided to exclude *Dailyintensities, DailyCalories, DailySteps* since the data was contained in *DailyActivity*.

I chose not to use the *HeartRate* and *WeightLogInfo* because they contained very little data. Less than 30 users had entered any information in the datasets.

### 4.1 Installing packages

The following packages will be used

```r
>
install.packages("dplyr") # a package to manipulate, clean and summarize unstructured data
install.packages("ggeasy") # provides aliases to commonly used but difficult to remember 'ggplot2' sequences
install.packages("ggplot2") # provides a system for producing statistical, or data, graphics
install.packages("ggrepel") # provides geoms for ggplot2 to repel overlapping text labelsS
install.packages("janitor") # provides simple functions for examining and cleaning dirty data
install.packages("lubridate") # a package that makes it easier to work with dates and times
install.packages("skimr") # provides summary statistics about variables in data frames, tibbles, data tables and vectors
install.packages("tidyverse") # provides essential R packages for data science
install.packages("waffle") # provides ability to create waffle chart visualizations
```

### 4.2 Load the libraries

```r
>
library(dplyr)
library(ggeasy)
library(ggplot2)
library(ggrepel)
library(lubridate)
library(janitor)
library(skimr)
library(tidyverse)
library(waffle)
```

### 4.3 Import files

The following tables will be imported:

![Alt text](/output/figs/tables_used.png?raw=True)
&nbsp;

```r
# import files into R environment
daily_activity <- read_csv("dailyActivity_merged.csv")
hourly_calories <- read_csv("hourlyCalories_merged.csv")
hourly_intensities <- read_csv("hourlyIntensities_merged.csv")
hourly_steps <- read_csv("hourlySteps_merged.csv")
```

### 4.4 Preview datasets

Preview selected data frames to get an understanding of the data and identify potential issues

```r
glimpse(daily_activity)
n_distinct(daily_activity$Id)
nrow(daily_activity)
```

<details>
 <summary>Results</summary>

```r
> glimpse(daily_activity)
Rows: 940
Columns: 15
$ Id                       <dbl> 1503960366, 1503960366, 1503960366,…
$ ActivityDate             <chr> "4/12/2016", "4/13/2016", "4/14/201…
$ TotalSteps               <dbl> 13162, 10735, 10460, 9762, 12669, 9…
$ TotalDistance            <dbl> 8.50, 6.97, 6.74, 6.28, 8.16, 6.48,…
$ TrackerDistance          <dbl> 8.50, 6.97, 6.74, 6.28, 8.16, 6.48,…
$ LoggedActivitiesDistance <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ VeryActiveDistance       <dbl> 1.88, 1.57, 2.44, 2.14, 2.71, 3.19,…
$ ModeratelyActiveDistance <dbl> 0.55, 0.69, 0.40, 1.26, 0.41, 0.78,…
$ LightActiveDistance      <dbl> 6.06, 4.71, 3.91, 2.83, 5.04, 2.51,…
$ SedentaryActiveDistance  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…
$ VeryActiveMinutes        <dbl> 25, 21, 30, 29, 36, 38, 42, 50, 28,…
$ FairlyActiveMinutes      <dbl> 13, 19, 11, 34, 10, 20, 16, 31, 12,…
$ LightlyActiveMinutes     <dbl> 328, 217, 181, 209, 221, 164, 233, …
$ SedentaryMinutes         <dbl> 728, 776, 1218, 726, 773, 539, 1149…
$ Calories                 <dbl> 1985, 1797, 1776, 1745, 1863, 1728,…

> n_distinct(daily_activity$Id) ## Unique:33
[1] 33

> nrow(daily_activity)
[1] 940
```

</details>
&nbsp;

```r
glimpse(hourly_calories)
n_distinct(hourly_calories$Id)
nrow(hourly_calories)
```

<details>
 <summary>Results</summary>

```r
> glimpse(hourly_calories)
Rows: 22,099
Columns: 3
$ Id           <dbl> 1503960366, 1503960366, 1503960366, 1503960366,…
$ ActivityHour <chr> "4/12/2016 12:00:00 AM", "4/12/2016 1:00:00 AM"…
$ Calories     <dbl> 81, 61, 59, 47, 48, 48, 48, 47, 68, 141, 99, 76…

> n_distinct(hourly_calories$Id)  ## Unique: 33
[1] 33

> nrow(hourly_calories)
[1] 22099
```

</details>

&nbsp;

```r
glimpse(hourly_intensities)
n_distinct(hourly_intensities$Id)
nrow(hourly_intensities)
```

<details>
 <summary>Results</summary>

 ```r
 > glimpse(hourly_intensities)
 Rows: 22,099
 Columns: 4
 $ Id               <dbl> 1503960366, 1503960366, 1503960366, 1503960…
 $ ActivityHour     <chr> "4/12/2016 12:00:00 AM", "4/12/2016 1:00:00…
 $ TotalIntensity   <dbl> 20, 8, 7, 0, 0, 0, 0, 0, 13, 30, 29, 12, 11…
 $ AverageIntensity <dbl> 0.333333, 0.133333, 0.116667, 0.000000, 0.0…


 > n_distinct(hourly_intensities$Id) ## Unique:33
 [1] 33
  > nrow(hourly_intensities)
 [1] 22099
 ```

</details>

&nbsp;

```r
glimpse(hourly_steps)
n_distinct(hourly_steps$Id)
nrow(hourly_steps)
```

<details>
 <summary>Results</summary>

 ```r
 > glimpse(hourly_steps)
 Rows: 22,099
 Columns: 3
 $ Id           <dbl> 1503960366, 1503960366, 1503960366, 1503960366,…
 $ ActivityHour <chr> "4/12/2016 12:00:00 AM", "4/12/2016 1:00:00 AM"…
 $ StepTotal    <dbl> 373, 160, 151, 0, 0, 0, 0, 0, 250, 1864, 676, 3…
  > n_distinct(hourly_steps$Id) ## Unique: 33
 [1] 33


 > nrow(hourly_steps)
 [1] 22099
 ```

</details>

&nbsp;

### 4.5 Cleaning and formatting

Check data for duplicate entries

```r
sum(daily_activity[duplicated(daily_activity), ])
sum(hourly_calories[duplicated(hourly_calories), ])
sum(hourly_intensities[duplicated(hourly_intensities), ])
sum(hourly_steps[duplicated(hourly_steps), ])
```

<details>
 <summary>Results</summary>

 ```r
> sum(daily_activity[duplicated(daily_activity), ])
[1] 0
> sum(hourly_calories[duplicated(hourly_calories), ])
[1] 0
> sum(hourly_intensities[duplicated(hourly_intensities), ])
[1] 0
> sum(hourly_steps[duplicated(hourly_steps), ])
[1] 0
```

</details>

&nbsp;

Check for NA values in data

```r
sum(is.na(daily_activity))
sum(is.na(hourly_calories))
sum(is.na(hourly_intensities))
sum(is.na(hourly_steps))
```

<details>
 <summary>Results</summary>

```r
> sum(is.na(daily_activity))
[1] 0
> sum(is.na(hourly_calories))
[1] 0
> sum(is.na(hourly_intensities))
[1] 0
> sum(is.na(hourly_steps))
[1] 0


```

</details>&nbsp;

After previewing the data I decided to merge all of the hourly data into one dataframe.

```r
## Merge all hourly into one dataset
hourly_data_df <- hourly_steps %>%
left_join(hourly_calories, by = c("Id", "ActivityHour")) %>%
left_join(hourly_intensities, by = c("Id", "ActivityHour"))
```

```r
## preview dataset
glimpse(hourly_data_df)
n_distinct(hourly_data_df$Id)
sum(hourly_data_df[duplicated(hourly_data_df), ])
sum(is.na(hourly_data_df))
```

<details>
 <summary>Results</summary>

```r
> glimpse(hourly_data_df)
Rows: 22,099
Columns: 6
$ Id               <dbl> 1503960366, 1503960366, 1503960366, 1503960…
$ ActivityHour     <chr> "4/12/2016 12:00:00 AM", "4/12/2016 1:00:00…
$ StepTotal        <dbl> 373, 160, 151, 0, 0, 0, 0, 0, 250, 1864, 67…
$ Calories         <dbl> 81, 61, 59, 47, 48, 48, 48, 47, 68, 141, 99…
$ TotalIntensity   <dbl> 20, 8, 7, 0, 0, 0, 0, 0, 13, 30, 29, 12, 11…
$ AverageIntensity <dbl> 0.333333, 0.133333, 0.116667, 0.000000, 0.0…
> n_distinct(hourly_data_df$Id) ## Unique: 33
[1] 33
> sum(is.na(hourly_data_df))
[1] 0
```

</details>&nbsp;

I then removed the individual hourly tables and the daily_steps table.

```r
rm(hourly_calories, hourly_intensities, hourly_steps)
```

&nbsp;

While previewing the data I noticed that the column names are in camel case. I changed them to snake case.

```r
daily_activity <- clean_names(daily_activity)
hourly_data_df <- clean_names(hourly_data_df)
```

<details>
 <summary>Results</summary>

```r
# Sample output
colnames(daily_activity)
[1] "id"                         "activity_date"            
[3] "total_steps"                "total_distance"           
[5] "tracker_distance"           "logged_activities_distance"
[7] "very_active_distance"       "moderately_active_distance"
[9] "light_active_distance"      "sedentary_active_distance"
[11] "very_active_minutes"        "fairly_active_minutes"    
[13] "lightly_active_minutes"     "sedentary_minutes"        
[15] "calories"   
```

</details>&nbsp;

Next I changed the stored date information from chr to datetime

```r
# change char to posix time
daily_activity$activity_date <-
  as.POSIXct(daily_activity$activity_date,
             format = "%m/%d/%Y",
             tz = Sys.timezone())

hourly_data_df$activity_hour <-
  as.POSIXct(hourly_data_df$activity_hour,
             format = "%m/%d/%Y %I:%M:%S %p",
             tz = Sys.timezone())

daily_activity$activity_date <-
  as.Date(daily_activity$activity_date,
          format = "%Y-%m-%d")
```

&nbsp;

Then the datetime in the hourly data was separated into two columns

```r
hourly_data_df$date <- as.Date(hourly_data_df$activity_hour)

hourly_data_df$time <-
  format(as.POSIXct(hourly_data_df$activity_hour), format = "%H:%M:%S")
```

<details>
 <summary>Results</summary>

 ```r
> class(daily_activity$activity_date)
[1] "Date"
class(hourly_data_df$date)
[1] "Date"
 ```

</details>&nbsp;

I also decided to add a new column to each dataframe that shows day of week

```r
daily_activity$day_of_week <-
 wday(daily_activity$activity_date, label = TRUE)

glimpse(daily_activity)
```

<details>
 <summary>Results</summary>

```r
Rows: 940
Columns: 16
$ id                         <dbl> 1503960366, 1503960366, 1503960366, 1503960366, 1503960366, 1503…
$ activity_date              <date> 2016-04-12, 2016-04-13, 2016-04-14, 2016-04-15, 2016-04-16, 201…
$ total_steps                <dbl> 13162, 10735, 10460, 9762, 12669, 9705, 13019, 15506, 10544, 981…
$ total_distance             <dbl> 8.50, 6.97, 6.74, 6.28, 8.16, 6.48, 8.59, 9.88, 6.68, 6.34, 8.13…
$ tracker_distance           <dbl> 8.50, 6.97, 6.74, 6.28, 8.16, 6.48, 8.59, 9.88, 6.68, 6.34, 8.13…
$ logged_activities_distance <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ very_active_distance       <dbl> 1.88, 1.57, 2.44, 2.14, 2.71, 3.19, 3.25, 3.53, 1.96, 1.34, 4.76…
$ moderately_active_distance <dbl> 0.55, 0.69, 0.40, 1.26, 0.41, 0.78, 0.64, 1.32, 0.48, 0.35, 1.12…
$ light_active_distance      <dbl> 6.06, 4.71, 3.91, 2.83, 5.04, 2.51, 4.71, 5.03, 4.24, 4.65, 2.24…
$ sedentary_active_distance  <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…
$ very_active_minutes        <dbl> 25, 21, 30, 29, 36, 38, 42, 50, 28, 19, 66, 41, 39, 73, 31, 78, …
$ fairly_active_minutes      <dbl> 13, 19, 11, 34, 10, 20, 16, 31, 12, 8, 27, 21, 5, 14, 23, 11, 28…
$ lightly_active_minutes     <dbl> 328, 217, 181, 209, 221, 164, 233, 264, 205, 211, 130, 262, 238,…
$ sedentary_minutes          <dbl> 728, 776, 1218, 726, 773, 539, 1149, 775, 818, 838, 1217, 732, 7…
$ calories                   <dbl> 1985, 1797, 1776, 1745, 1863, 1728, 1921, 2035, 1786, 1775, 1827…
$ day_of_week                <ord> Tue, Wed, Thu, Fri, Sat, Sun, Mon, Tue, Wed, Thu, Fri, Sat, Sun,…
```

</details>&nbsp;

```r
hourly_data_df$day_of_week <-
 wday(hourly_data_df$date, label = TRUE)

glimpse(hourly_data_df)
```

<details>
 <summary>Results</summary>

```r
Rows: 22,099
Columns: 8
$ id                <dbl> 1503960366, 1503960366, 1503960366, 1503960366, 1503960366, 1503960366, 1…
$ date              <date> 2016-04-12, 2016-04-12, 2016-04-12, 2016-04-12, 2016-04-12, 2016-04-12, …
$ time              <times> 00:00:00, 01:00:00, 02:00:00, 03:00:00, 04:00:00, 05:00:00, 06:00:00, 0…
$ step_total        <dbl> 373, 160, 151, 0, 0, 0, 0, 0, 250, 1864, 676, 360, 253, 221, 1166, 2063, …
$ calories          <dbl> 81, 61, 59, 47, 48, 48, 48, 47, 68, 141, 99, 76, 73, 66, 110, 151, 76, 83…
$ total_intensity   <dbl> 20, 8, 7, 0, 0, 0, 0, 0, 13, 30, 29, 12, 11, 6, 36, 58, 13, 16, 29, 39, 4…
$ average_intensity <dbl> 0.333333, 0.133333, 0.116667, 0.000000, 0.000000, 0.000000, 0.000000, 0.0…
$ day_of_week       <ord> Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue, Tue…
```

</details>

***

## 5.Analyze and Share

As highlighted in the preparation phase, there were concerns regarding the data utilized, indicating a need to consider that the analysis results might not be applicable due to the limited sample size and available data entries

I used the summary() function to return basic statistical calculations for all the columns in the dataframe _daily_activity_. From this overview I quickly identified the averages for the following columns that I'm interested in:

* The average totals steps is 7638
* The average total distance is 5.49
* The average calories burned is 2304

```r
> summary(daily_activity)


        id            activity_date         total_steps    total_distance   tracker_distance
Min.   :1.504e+09   Min.   :2016-04-12   Min.   :    0   Min.   : 0.000   Min.   : 0.000 
1st Qu.:2.320e+09   1st Qu.:2016-04-19   1st Qu.: 3790   1st Qu.: 2.620   1st Qu.: 2.620 
Median :4.445e+09   Median :2016-04-26   Median : 7406   Median : 5.245   Median : 5.245 
Mean   :4.855e+09   Mean   :2016-04-26   Mean   : 7638   Mean   : 5.490   Mean   : 5.475 
3rd Qu.:6.962e+09   3rd Qu.:2016-05-04   3rd Qu.:10727   3rd Qu.: 7.713   3rd Qu.: 7.710 
Max.   :8.878e+09   Max.   :2016-05-12   Max.   :36019   Max.   :28.030   Max.   :28.030 
                                                                                         
logged_activities_distance very_active_distance moderately_active_distance light_active_distance
Min.   :0.0000             Min.   : 0.000       Min.   :0.0000             Min.   : 0.000      
1st Qu.:0.0000             1st Qu.: 0.000       1st Qu.:0.0000             1st Qu.: 1.945      
Median :0.0000             Median : 0.210       Median :0.2400             Median : 3.365      
Mean   :0.1082             Mean   : 1.503       Mean   :0.5675             Mean   : 3.341      
3rd Qu.:0.0000             3rd Qu.: 2.053       3rd Qu.:0.8000             3rd Qu.: 4.782      
Max.   :4.9421             Max.   :21.920       Max.   :6.4800             Max.   :10.710      
                                                                                               
sedentary_active_distance very_active_minutes fairly_active_minutes lightly_active_minutes
Min.   :0.000000          Min.   :  0.00      Min.   :  0.00        Min.   :  0.0        
1st Qu.:0.000000          1st Qu.:  0.00      1st Qu.:  0.00        1st Qu.:127.0        
Median :0.000000          Median :  4.00      Median :  6.00        Median :199.0        
Mean   :0.001606          Mean   : 21.16      Mean   : 13.56        Mean   :192.8        
3rd Qu.:0.000000          3rd Qu.: 32.00      3rd Qu.: 19.00        3rd Qu.:264.0        
Max.   :0.110000          Max.   :210.00      Max.   :143.00        Max.   :518.0        
                                                                                         
sedentary_minutes    calories    day_of_week
Min.   :   0.0    Min.   :   0   Sun:121   
1st Qu.: 729.8    1st Qu.:1828   Mon:120   
Median :1057.5    Median :2134   Tue:152   
Mean   : 991.2    Mean   :2304   Wed:150   
3rd Qu.:1229.5    3rd Qu.:2793   Thu:147   
Max.   :1440.0    Max.   :4900   Fri:126   
                                 Sat:124   
```

&nbsp;

I applied the same function to the _hourly_data_ dataframe.

* The average total steps is 320
* The average calories burned is 97.39 

```r
> summary(hourly_data_df)


        id                 date                 time            step_total         calories    
Min.   :1.504e+09   Min.   :2016-04-12   Min.   :00:00:00   Min.   :    0.0   Min.   : 42.00 
1st Qu.:2.320e+09   1st Qu.:2016-04-19   1st Qu.:05:00:00   1st Qu.:    0.0   1st Qu.: 63.00 
Median :4.445e+09   Median :2016-04-26   Median :11:00:00   Median :   40.0   Median : 83.00 
Mean   :4.848e+09   Mean   :2016-04-26   Mean   :11:24:57   Mean   :  320.2   Mean   : 97.39 
3rd Qu.:6.962e+09   3rd Qu.:2016-05-03   3rd Qu.:17:00:00   3rd Qu.:  357.0   3rd Qu.:108.00 
Max.   :8.878e+09   Max.   :2016-05-12   Max.   :23:00:00   Max.   :10554.0   Max.   :948.00 

total_intensity  average_intensity day_of_week
Min.   :  0.00   Min.   :0.0000    Sun:2896  
1st Qu.:  0.00   1st Qu.:0.0000    Mon:2861  
Median :  3.00   Median :0.0500    Tue:3600  
Mean   : 12.04   Mean   :0.2006    Wed:3547  
3rd Qu.: 16.00   3rd Qu.:0.2667    Thu:3283  
Max.   :180.00   Max.   :3.0000    Fri:2997  
                                   Sat:2915  
```

&nbsp;

I wanted to review the average steps by day of week, so I grouped values by the day_of_week column in order to summarize the data. From the output of summarise(), we are able to identify the days with the highest average steps and the lowest average steps.

* Highest: Saturday with 8153 average steps
* Lowest: Sunday with 6933 average steps

```r
daily_activity %>%
 group_by(day_of_week) %>%
 summarise(avg_steps = round(mean(total_steps)))

 day_of_week   avg_steps
 <ord>           <dbl>
1 Sun              6933
2 Mon              7781
3 Tue              8125
4 Wed              7559
5 Thu              7406
6 Fri              7448
7 Sat              8153
```
&nbsp;

According to a study reported on in 2021 by [NBC news](https://www.nbcnews.com/health/health-news/how-many-steps-day-should-you-take-study-finds-7-n1278853), "people appeared to gain more health benefits the more steps they took, with the greatest statistically significant reduction in mortality risk between 7,000 and 10,000 steps". As seen in the averages from the dataset, most users met the lower end of the steps range and reduce their mortality risk.

&nbsp;

To visualize the results, I created the following graph using ggplot2. At a quick glance, it is noticable that the average steps by day are relatively close to each other.

```r
ggplot(daily_activity, aes(x = day_of_week, y = total_steps)) +
 geom_bar(stat = "summary",
          fun = "mean",
          fill = "#00abff") +
 labs(title = "Average Steps By Day Of Week",
      x = "Day of Week", y = "Average Steps") +
 ggeasy::easy_center_title()


```

![Alt text](/output/plots/avg_steps%20by%20day%20of%20week.png?raw=true)

&nbsp;

### Correlation between total steps and calories

Next, I wanted to look at the correlation between the total number of steps and the amount of calories burned. 
Using the cor() function, I obtained the Pearson Correlation between the total steps and calories burned. 
I obtained 0.5915681 as the output using the _daily_activity_ dataframe. With this information, it can be noted that there is a moderately strong positive correlation between the two. It suggests that there is a noticeable and moderately strong relationship between them. As the user takes more steps, the amount of calories burned also increases.

```r
cor(daily_activity$total_steps, daily_activity$calories)
[1] 0.5915681


ggplot(data=daily_activity) +
 geom_point(mapping=aes(x=total_steps, y=calories)) +
 geom_smooth(mapping=aes(x=total_steps, y=calories)) +
 labs(title="Correlation Between Total Steps and Calories Burned",
     x="Total Steps", y="Calories Burned")


```

![Alt text](/output/plots/total_steps%20and%20calories.png?raw=true)

### Correlation between total distance and calories

I also wanted to look at the correlation between the total distance a user walked and the amount of calories burned. 
Using the cor() function for these two, I obtained a value of [1] 0.6449619 returned. There is also a noticeable and moderately strong positive relationship between the two. The longer the distance a user travels, the more calories are burned.

```r
cor(daily_activity$total_distance, daily_activity$calories)
[1] 0.6449619


ggplot(data=daily_activity) +
 geom_point(mapping=aes(x=total_distance, y=calories)) +
 geom_smooth(mapping=aes(x=total_distance, y=calories)) +
 labs(title="Correlation Between Total Distance and Calories Burned",
     x="Distance(km)", y="Calories Burned")
```

![Alt text](/output/plots/distance%20and%20calories.png?raw=true)

### Device usage breakdown

With the dataset provided, I was able to group users by device usage. I defined low use as a device user who had 1 to 14 days where the device registered, or had manually entered data, activity. Moderate use is 15 to 22 days and high use being from 23 to 31 days. The following results displays the breakdown:

```r
dau_use <- daily_activity %>%
 left_join(dau_breakdown, by = "id") %>%
 group_by(device_usage) %>%
 summarise(participants = n_distinct(id)) %>%
 mutate(perc = participants / sum(participants)) %>%
 arrange(perc) %>%
 mutate(perc = scales::percent(perc))
head(dau_use)
```

Results

```r
 device_usage                 participants perc
 <fct>                               <int> <chr>
1 Low Use - 1 to 14 days                  3 9.1%
2 Moderate Use - 15 to 22 days            6 18.2%
3 High Use - 23 to 31 days               24 72.7%
```

```r
dau_breakdown <- daily_activity %>%
 filter(total_steps > 500) %>%
 group_by(id) %>%
 summarize(activity_date = sum(n())) %>%
 mutate(device_usage = case_when(
   activity_date >= 1 & activity_date <= 14 ~ "Low Use - 1 to 14 days",
   activity_date >= 15 & activity_date <= 22 ~ "Moderate Use - 15 to 22 days",
   activity_date >= 23 & activity_date <= 31 ~ "High Use - 23 to 31 days")) %>%
 mutate(device_usage = factor(
   device_usage,
   level = c(
     "Low Use - 1 to 14 days",
     "Moderate Use - 15 to 22 days",
     "High Use - 23 to 31 days"
   )
 )) %>%
 rename(daysused = activity_date) %>%
 group_by(device_usage)
```

Most of the users that participated in the study fall into the high use category. The following chart displays the device usage findings.
&nbsp;

```r
waffle(
 dau_use,
 rows = 3,
 size = 0.33,
 colors = c("#D55E00", "#0072B2", "#009E73"),
 legend_pos = "bottom"
) +
 labs(title = "Device Usage",
      subtitle = "1 square = 1 Participant",) +
 ggeasy::easy_center_title()
```

![Alt text](/output/figs/waffle.png?raw=true)

### Time of different activity types

Alongside device usage, I was able to group activity types by the amount of minutes that are spent in that state. I looked at the activity types as a whole throughout the study. The activity types available were very active, fairly active, lightly active and sedentary.

```r
# get totals from daily activity for each type
very_active_min <- sum(daily_activity$very_active_minutes)
fairly_active_min <- sum(daily_activity$fairly_active_minutes)
lightly_active_min <- sum(daily_activity$lightly_active_minutes)
sedentary_min <- sum(daily_activity$sedentary_minutes)

# create chart slices and labels
activity_vec <- c(very_active_min, fairly_active_min,
                lightly_active_min, sedentary_min)

label_vec <- c("Very Active", "Fairly Active", "Lightly Active", "Sedentary")
piepercent <- round(100 * activity_vec / sum(activity_vec), 1)

pie_data <- data.frame(activity_vec, label_vec, piepercent)

## get positions
pie_pos <- pie_data %>%
 mutate(csum = rev(cumsum(rev(activity_vec))),
        pos = activity_vec / 2 + lead(csum, 1),
        pos = if_else(is.na(pos), activity_vec / 2, pos))

## display chart
ggplot(pie_data, aes(x = "", y = activity_vec, fill = fct_inorder(label_vec))) +
 ggtitle("Percentage of Activity in Minutes") +
 geom_col(width = 1, color = 1) +
 coord_polar(theta = "y") +
 scale_fill_brewer(palette = "Set3") +
 geom_label_repel(data = pie_pos,
                  aes(y = pos, label = paste0(piepercent, "%")),
                  size = 4.5, nudge_x = 1, show.legend = FALSE) +
 guides(fill = guide_legend(title = "Activity Type")) +
 theme_void() +
 ggeasy::easy_center_title()
```

![Alt text](/output/figs/percentage%20of%20activity.png?raw=true)

The activity type with the highest amount of time was the sedentary type.

 After examining the results from device usage and activity type, I saw that although most users had high device usage, most of the activity was registered as sedentary.

### Hourly Heatmap

I created an hourly heatmap in Tableau to see the average steps taken by hour each day of the week. It can be noted that most users began to get their steps in around 8:00 AM and continued until around 7:00 PM. That's around 11 hours of time that users were able to walk. Also noticeable, the hours leading up to 7:00 PM show higher activity, except for Saturday where the hours between 11:00 AM and 3:00 PM have the most activity.  

![Alt text](/output/figs/hourly%20heatmap.png)

I exported the hourly data to a file in my capstone project directory

```r
write_csv(hourly_data_df, "../R/Capstone_Project/hourly_data.csv")
```

From the results of the data analysis, I was able to see that on average people are meeting the updated recommended steps.

Looking at device usage and activity type, most users are recording data with their devices. The majority of the users that participated in the study were in the high use category, using their devices 23 to 31 days. 
As a note, we see that users have 11 hours of active time and 13 hours of sedentary time. It may provide a reason as to why the percentage of activity minutes for sedentary time was higher than the rest. 

## 6.Act (Recommendations)

* The Bellabeat team should emphasize the sleep and weight tracking that the device has to offer. It may be necessary to update the capabilities of the devices in order to make it easier for the device to register these activities or for users to manually input the information.
* To encourage the user to use the device:
  * the device should show their current number of steps compared to their historical average and goal
  * The device could have an "achievement" feature that challenges the user to take more steps
  * Offer challenges where the user can meet a goal and receive discounts for products or services. This could help increase the amount of data that is either recorded or manually entered by the user
  * Set peer to peer challenges. Display a scoreboard when the user shares data with family or friends
* An optional pop up can be added to remind the user to walk when they are sedentary for a set amount of time
